import pandas as pd
import pickle
import os

from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.pipeline import Pipeline
from sklearn.ensemble import RandomForestClassifier

# 1. CÄƒi cÄƒtre fiÈ™iere
DATA_PATH = r'd:\01 Link Academy\Curs si suport curs Link Academy\Task-uri\Task machine learning 3\ml_product_classification\data\products_features.csv'
MODEL_PATH = os.path.join('..', 'models', 'model.pkl')

# 2. ÃncÄƒrcarea È™i validarea datelor
try:
    df = pd.read_csv(DATA_PATH)
    print("ğŸ“¥ FiÈ™ierul a fost Ã®ncÄƒrcat cu succes.")
except FileNotFoundError:
    print(f"âŒ FiÈ™ierul nu a fost gÄƒsit la calea: {DATA_PATH}")
    exit()

# 3. Verificare coloane esenÈ›iale
required_columns = ['Clean Title', 'Category Label']
if not all(col in df.columns for col in required_columns):
    print(f"âŒ FiÈ™ierul trebuie sÄƒ conÈ›inÄƒ coloanele: {required_columns}")
    exit()

# 4. CurÄƒÈ›are date
df = df[required_columns].dropna()
df['Clean Title'] = df['Clean Title'].astype(str).fillna('')

# 5. Separare caracteristici È™i etichete
X = df['Clean Title']
y = df['Category Label']

# 6. ÃmpÄƒrÈ›irea Ã®n seturi de antrenare È™i testare
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# 7. Pipeline: TF-IDF + Random Forest
pipeline = Pipeline([
    ('tfidf', TfidfVectorizer(max_features=5000)),
    ('clf', RandomForestClassifier(n_estimators=100, random_state=42))
])

# 8. Antrenarea modelului
print("ğŸ” Antrenare model...")
pipeline.fit(X_train, y_train)
print("âœ… Model antrenat cu succes.")

# 9. Salvarea modelului
try:
    with open(MODEL_PATH, 'wb') as f:
        pickle.dump(pipeline, f)
    print(f"ğŸ’¾ Modelul a fost salvat Ã®n: {MODEL_PATH}")
except Exception as e:
    print(f"âŒ Eroare la salvarea modelului: {e}")
